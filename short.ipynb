{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function for creating shorts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Total narration exceeds target duration. Consider splitting text.\n",
      "Moviepy - Building video Final_product/1 hour 20 minutes of relaxing Minecraft Parkour (Nostalgia, Scenery, No Ads)_3_narrated.mp4.\n",
      "MoviePy - Writing audio in 1 hour 20 minutes of relaxing Minecraft Parkour (Nostalgia, Scenery, No Ads)_3_narratedTEMP_MPY_wvf_snd.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                      \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MoviePy - Done.\n",
      "Moviepy - Writing video Final_product/1 hour 20 minutes of relaxing Minecraft Parkour (Nostalgia, Scenery, No Ads)_3_narrated.mp4\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moviepy - Done !\n",
      "Moviepy - video ready Final_product/1 hour 20 minutes of relaxing Minecraft Parkour (Nostalgia, Scenery, No Ads)_3_narrated.mp4\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "from moviepy.editor import VideoFileClip, TextClip, CompositeVideoClip, concatenate_audioclips, AudioFileClip, CompositeAudioClip\n",
    "import pyttsx3\n",
    "\n",
    "def split_text_into_parts(text, max_length=30):\n",
    "    words = text.split()\n",
    "    parts = []\n",
    "    current_part = []\n",
    "    current_length = 0\n",
    "    \n",
    "    for word in words:\n",
    "        if current_length + len(word) > max_length:\n",
    "            parts.append(' '.join(current_part))\n",
    "            current_part = [word]\n",
    "            current_length = len(word)\n",
    "        else:\n",
    "            current_part.append(word)\n",
    "            current_length += len(word) + 1\n",
    "    \n",
    "    if current_part:\n",
    "        parts.append(' '.join(current_part))\n",
    "    \n",
    "    return parts\n",
    "\n",
    "def text_to_speech_pyttsx3(text, output_path):\n",
    "    engine = pyttsx3.init()\n",
    "    engine.setProperty('rate', 180)  # Adjust as needed\n",
    "    engine.setProperty('volume', 0.9)  # Adjust as needed\n",
    "    engine.setProperty('voice', 'com.apple.speech.synthesis.voice.samantha.premium')\n",
    "    engine.save_to_file(text, output_path)\n",
    "    engine.runAndWait()\n",
    "\n",
    "def create_short_with_narration(video_path, text, output_folder, target_duration=57):\n",
    "    video_clip = VideoFileClip(video_path)\n",
    "\n",
    "    # Crop the video to a 9:16 aspect ratio if necessary\n",
    "    target_aspect_ratio = 9.0 / 16.0\n",
    "    if video_clip.w / video_clip.h > target_aspect_ratio:\n",
    "        new_width = int(video_clip.h * target_aspect_ratio)\n",
    "        crop_x = (video_clip.w - new_width) // 2\n",
    "        video_clip = video_clip.crop(x1=crop_x, width=new_width)\n",
    "    \n",
    "    text_parts = split_text_into_parts(text)\n",
    "    narration_clips = []\n",
    "    text_clips = []\n",
    "    \n",
    "    # Create temporary narration and text clips\n",
    "    for part in text_parts:\n",
    "        with tempfile.NamedTemporaryFile(delete=True, suffix='.wav') as temp_audio:\n",
    "            text_to_speech_pyttsx3(part, temp_audio.name)\n",
    "            narration_clip = AudioFileClip(temp_audio.name)\n",
    "            narration_clips.append(narration_clip)\n",
    "            \n",
    "            # Assume the duration of each text part is the same as its narration clip\n",
    "            text_clip = TextClip(part, fontsize=40, color='white', font='Arial-Bold',align='center', size=(video_clip.w, 100))\n",
    "            text_clip = text_clip.set_duration(narration_clip.duration)\n",
    "            text_clip = text_clip.set_position('center').set_duration(narration_clip.duration)\n",
    "            text_clips.append(text_clip)\n",
    "\n",
    "    # Calculate total narration duration and adjust video duration accordingly\n",
    "    total_narration_duration = sum([clip.duration for clip in narration_clips])\n",
    "    if total_narration_duration > target_duration:\n",
    "        print(\"Warning: Total narration exceeds target duration. Consider splitting text.\")\n",
    "    \n",
    "    # Loop or trim the video to match the target duration\n",
    "    if video_clip.duration < target_duration:\n",
    "        video_clip = video_clip.loop(duration=target_duration)\n",
    "    else:\n",
    "        video_clip = video_clip.subclip(0, target_duration)\n",
    "    \n",
    "    # Set start times for text and narration clips to sequentially appear\n",
    "    start_time = 0\n",
    "    for i, clip in enumerate(narration_clips):\n",
    "        narration_clips[i] = clip.set_start(start_time)\n",
    "        text_clips[i] = text_clips[i].set_start(start_time)\n",
    "        start_time += clip.duration\n",
    "    \n",
    "    # Combine narration clips into a single audio track and mix with original audio\n",
    "    combined_narration = concatenate_audioclips(narration_clips)\n",
    "    mixed_audio = CompositeAudioClip([video_clip.audio, combined_narration])\n",
    "    video_clip.audio = mixed_audio\n",
    "    \n",
    "    # Create final clip with video and overlaid text\n",
    "    final_clip = CompositeVideoClip([video_clip] + text_clips, size=video_clip.size).set_duration(target_duration)\n",
    "    \n",
    "    # Output\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "    output_filename = os.path.basename(video_path).replace(\".mp4\", \"_narrated.mp4\")\n",
    "    output_path = os.path.join(output_folder, output_filename)\n",
    "    \n",
    "    final_clip.write_videofile(output_path, codec=\"libx264\", audio_codec=\"aac\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "text = \"In Python, classes act as blueprints for creating objects. They define a set of attributes (variables that hold data) and methods (functions that define behaviors) that their objects will embody. A class encapsulates data for the object it creates, ensuring a modular and organized approach to programming. When a class is defined, it doesn’t create an actual object but rather specifies what attributes and methods the objects of that class should have. Objects are instances of classes; when you instantiate a class, you’re creating a unique object with its own specific state based on the class's blueprint. This allows for individual objects to possess their own characteristics and behaviors, enabling programmers to model real-world scenarios in a structured and intuitive way. Python's class and object mechanism facilitate data abstraction, encapsulation, inheritance, and polymorphism, making it powerful for developing complex applications.\"\n",
    "create_short_with_narration(\"Clips_for_edit/1 hour 20 minutes of relaxing Minecraft Parkour (Nostalgia, Scenery, No Ads)_3.mp4\", text, \"Final_product\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Managing shorts and posting them on social media"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pyyoutube import Api as YouTubeApi\n",
    "from tiktokpy import TikTokPy\n",
    "from instabot import Bot\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Get API keys from environment variables\n",
    "youtube_api_key = os.getenv(\"YOUTUBE_API_KEY\")\n",
    "tiktok_api_key = os.getenv(\"TIKTOK_API_KEY\")\n",
    "instagram_username = os.getenv(\"INSTAGRAM_USERNAME\")\n",
    "instagram_password = os.getenv(\"INSTAGRAM_PASSWORD\")\n",
    "\n",
    "# Connect to YouTube API\n",
    "youtube_api = YouTubeApi(api_key=youtube_api_key)\n",
    "\n",
    "# Connect to TikTok API\n",
    "tiktok_api = TikTokPy(api_key=tiktok_api_key)\n",
    "\n",
    "# Connect to Instagram API\n",
    "instagram_bot = Bot()\n",
    "instagram_bot.login(username=instagram_username, password=instagram_password)\n",
    "\n",
    "# Get the path of the short video file\n",
    "short_video_path = \"Final_product/short_video.mp4\"\n",
    "\n",
    "# Post the short video on YouTube\n",
    "youtube_api.upload_video(file_path=short_video_path, title=\"Short Video\", description=\"Check out this short video!\")\n",
    "\n",
    "# Post the short video on TikTok\n",
    "tiktok_api.upload_video(file_path=short_video_path, caption=\"Check out this short video!\")\n",
    "\n",
    "# Post the short video on Instagram\n",
    "instagram_bot.upload_photo(photo=short_video_path, caption=\"Check out this short video!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Things to install if you want to run the code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#pip install gtts\n",
    "#pip install moviepy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating database with 60 seconds clip from a longer video yay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ[\"IMAGEIO_FFMPEG_EXE\"] = \"/opt/homebrew/lib/python3.11/site-packages/ffmpeg\"\n",
    "from moviepy.editor import VideoFileClip\n",
    "\n",
    "\n",
    "def Cut_Into_Shorts(directory_with_long_Videos, directory_with_shorts):\n",
    "    # Get a list of video files in the directory\n",
    "    video_files = [f for f in os.listdir(directory_with_long_Videos) if f.endswith('.mp4')]\n",
    "    \n",
    "    # Iterate over each video file\n",
    "    for video_file in video_files:\n",
    "        # Get the full path of the video file\n",
    "        video_path = os.path.join(directory_with_long_Videos, video_file)\n",
    "        \n",
    "        # Create a VideoFileClip object\n",
    "        video_clip = VideoFileClip(video_path)\n",
    "        \n",
    "        # Calculate the duration of the video clip in seconds\n",
    "        video_duration = video_clip.duration\n",
    "        \n",
    "        # Calculate the number of 60-second clips\n",
    "        num_clips = int(video_duration // 60)\n",
    "        \n",
    "        # Iterate over each 60-second clip\n",
    "        for i in range(num_clips):\n",
    "            # Calculate the start and end time of the clip\n",
    "            start_time = i * 60\n",
    "            end_time = (i + 1) * 60\n",
    "            \n",
    "            # Extract the clip from the video\n",
    "            clip = video_clip.subclip(start_time, end_time)\n",
    "            \n",
    "            # Generate the output file name\n",
    "            output_file = f\"{video_file.split('.')[0]}_{i+1}.mp4\"\n",
    "            \n",
    "            # Save the clip to the output directory\n",
    "            clip.write_videofile(os.path.join(directory_with_shorts, output_file))\n",
    "        \n",
    "        # Close the video clip object\n",
    "        video_clip.close()\n",
    "\n",
    "# Example usage\n",
    "Cut_Into_Shorts(\"Raw_material\", \"Clips_for_edit\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for voice in voices:\\n    if [\\'en_US\\'] == voice.languages:\\n        print(voice.languages)\\n        print(voice, voice.id)\\n        engine.setProperty(\\'voice\\', voice.id)\\n        engine.setProperty(\\'rate\\', 180)  # Adjust as needed\\n        engine.setProperty(\\'volume\\', 0.9)  # Adjust as needed\\n        engine.say(\"Hello World! This is a test.\")\\n        engine.runAndWait()\\n        engine.stop()\\n    else:\\n        pass\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import tempfile\n",
    "from moviepy.editor import VideoFileClip, TextClip, CompositeVideoClip, concatenate_audioclips, AudioFileClip, CompositeAudioClip\n",
    "import pyttsx3\n",
    "engine = pyttsx3.init()\n",
    "voices = engine.getProperty('voices')\n",
    "engine.setProperty('voice', 'com.apple.speech.synthesis.voice.samantha.premium')\n",
    "engine.setProperty('rate', 180)  # Adjust as needed\n",
    "engine.setProperty('volume', 0.9)  # Adjust as needed\n",
    "engine.say(\"Hello World! This is a test.\")\n",
    "engine.runAndWait()\n",
    "\"\"\"for voice in voices:\n",
    "    if ['en_US'] == voice.languages:\n",
    "        print(voice.languages)\n",
    "        print(voice, voice.id)\n",
    "        engine.setProperty('voice', voice.id)\n",
    "        engine.setProperty('rate', 180)  # Adjust as needed\n",
    "        engine.setProperty('volume', 0.9)  # Adjust as needed\n",
    "        engine.say(\"Hello World! This is a test.\")\n",
    "        engine.runAndWait()\n",
    "        engine.stop()\n",
    "    else:\n",
    "        pass\n",
    "\"\"\"\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
